{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d766322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from os import listdir, getcwd\n",
    "from os.path import join, dirname\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0a524",
   "metadata": {},
   "source": [
    "# Assemblee nationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSeance(path, document: str):\n",
    "    path = join(path, document)  # generate full path\n",
    "    seance = etree.parse(path)  # missing argument error can be ignored\n",
    "\n",
    "    # extract metadata\n",
    "    legislature = seance.find(\n",
    "        \".//{http://schemas.assemblee-nationale.fr/referentiel}legislature\"\n",
    "    ).text\n",
    "    date = seance.find(\n",
    "        \".//{http://schemas.assemblee-nationale.fr/referentiel}dateSeance\"\n",
    "    ).text\n",
    "\n",
    "    # init list for text extraction\n",
    "    text_list = []\n",
    "\n",
    "    # loop over all speakers\n",
    "    for a in seance.findall(\n",
    "        \".//{http://schemas.assemblee-nationale.fr/referentiel}orateur\"\n",
    "    ):\n",
    "        paragraphe = (\n",
    "            a.getparent().getparent()\n",
    "        )  # the paragraph is two nodes up from the speaker\n",
    "        if (\n",
    "            paragraphe.tag\n",
    "            != \"{http://schemas.assemblee-nationale.fr/referentiel}paragraphe\"\n",
    "        ):  # this basically catches a \"vote\" result block\n",
    "            continue\n",
    "        valeur_ptsodj = paragraphe.get(\"valeur_ptsodj\")  # ordre du jour\n",
    "        code_grammaire = paragraphe.get(\"code_grammaire\")  # type of speech\n",
    "        ordre_absolu_seance = paragraphe.get(\"ordre_absolu_seance\")  # index number\n",
    "        ordinal_prise = paragraphe.get(\"ordinal_prise\")  # another index number\n",
    "        orateur_name = a.find(\n",
    "            \"{http://schemas.assemblee-nationale.fr/referentiel}nom\"\n",
    "        )  # name of the speaker\n",
    "        orateur_name_str = etree.tostring(\n",
    "            orateur_name, method=\"text\", encoding=\"unicode\"\n",
    "        ).strip()\n",
    "        orateur_id = a.find(\n",
    "            \"{http://schemas.assemblee-nationale.fr/referentiel}id\"\n",
    "        )  # id of the speaker\n",
    "        orateur_ref = a.find(\n",
    "            \"{http://schemas.assemblee-nationale.fr/referentiel}acteurRef\"\n",
    "        )  # this is only to catch errors with the 15th legislature\n",
    "        if orateur_id is not None:\n",
    "            orateur_id = orateur_id\n",
    "        elif orateur_ref is not None:\n",
    "            orateur_id = orateur_ref\n",
    "        else:\n",
    "            orateur_id = etree.fromstring(\n",
    "                text=\"<orateur>None</orateur>\"\n",
    "            )  # default to None if nothing found\n",
    "        orateur_id_str = etree.tostring(\n",
    "            orateur_id, method=\"text\", encoding=\"unicode\"\n",
    "        ).strip()\n",
    "        content = paragraphe.find(\n",
    "            \"{http://schemas.assemblee-nationale.fr/referentiel}texte\"\n",
    "        )  # extract the text\n",
    "        content_str = etree.tostring(content, method=\"text\", encoding=\"unicode\").strip()\n",
    "        talking = {\n",
    "            \"legislature\": legislature,\n",
    "            \"nom_fichier\": document,\n",
    "            \"date\": date,\n",
    "            \"orateur_name\": orateur_name_str,\n",
    "            \"orateur_id\": orateur_id_str,\n",
    "            \"ordre_absolu_seance\": int(ordre_absolu_seance),\n",
    "            \"valeur_ptsodj\": int(valeur_ptsodj),\n",
    "            \"ordinal_prise\": ordinal_prise,\n",
    "            \"code_grammaire\": code_grammaire,\n",
    "            \"content\": content_str,\n",
    "        }\n",
    "        text_list.append(talking)\n",
    "    return text_list  # returns a list of all speech nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd20304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip Assemblee nationale opendata and keep only \"compteRendu\" and put them in \"data/assemblee_nationale\"\n",
    "folders = [\"15_compteRendu\", \"16_compteRendu\", \"17_compteRendu\"]\n",
    "root_folder = dirname(dirname(getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7514847",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    path = join(root_folder, \"data\", \"assemblee_nationale\", folder)\n",
    "    for f in listdir(path):\n",
    "        if (f == 'CRSJOCGR5L15S2017E1N001.xml') | (f == '.DS_Store'): # this file is a duplicate, so we exclude it\n",
    "            continue\n",
    "        cr = parseSeance(path, f)\n",
    "        all_cr.extend(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42edb31",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b20384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame(all_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73944d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning \n",
    "df[\"date\"] = df[\"date\"].str[:12]\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"date\"])\n",
    "match_weird_punctuation = re.compile(r'([!\\.,)?])(?=\\w)')\n",
    "df['content'] = df['content'].str.replace(match_weird_punctuation, r'\\1 ', regex=True) # catches punctuation errors\n",
    "df['content'] = df['content'].str.replace('\\xa0', ' ') # catches white spaces\n",
    "df['content'] = df['content'].str.replace('gouvernement', 'Gouvernement') # both spellings exist in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grouped df to take into account interruptions\n",
    "# Groups by \"ordinal_prise\" (speech) and only if it's not an \"interruption\"\n",
    "\n",
    "df_paroles = df.loc[~(df[\"code_grammaire\"].str.contains(\"interruption\", case=False))]\n",
    "df_rest = df.loc[(df[\"code_grammaire\"].str.contains(\"interruption\", case=False))]\n",
    "\n",
    "df_grouped = (\n",
    "    df_paroles.groupby(['legislature', 'datetime', 'nom_fichier', 'orateur_id', 'ordinal_prise'], as_index=False)\n",
    "    .agg({\n",
    "        'orateur_name': 'first',\n",
    "        'content': ' '.join,\n",
    "        'ordre_absolu_seance': list,\n",
    "        'code_grammaire': 'first'\n",
    "    })\n",
    ")\n",
    "\n",
    "df_grouped = pd.concat([df_grouped, df_rest], ignore_index=True)\n",
    "df_grouped = df_grouped.sort_values(\n",
    "    by=[\"datetime\", \"valeur_ptsodj\", \"ordre_absolu_seance\"],\n",
    "    key=lambda col: col.map(\n",
    "        lambda x: (\n",
    "            x\n",
    "            if col.name == \"datetime\"\n",
    "            else (\n",
    "                x\n",
    "                if col.name == \"valeur_ptsodj\"\n",
    "                else (x[0] if isinstance(x, list) and len(x) > 0 else float(x))\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    ").reset_index(drop=True)\n",
    "df_grouped = df_grouped.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a631730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun stats\n",
    "# df.loc[df[\"code_grammaire\"].str.contains(\"PAROLE\")][\"content\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf19ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by keywords\n",
    "\n",
    "df_vsa = df_grouped.loc[\n",
    "    df_grouped[\"content\"].str.contains(\"vidéo-surveillance\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"vidéo-protection\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"vidéosurveillance\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"vidéoprotection\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"vie privée\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"RGPD\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"VSA\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"surveillance\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"protection des données\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\" data \", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"open-data\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"opendata\", case=False)\n",
    "].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76296ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df, df_grouped, df_paroles, df_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(cr, all_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vsa.to_pickle(join(root_folder, \"data\", \"assemblee_nationale\", \"df_mots_cles.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2202c7ac",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wtpsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40701098",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = dirname(dirname(getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59206d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vsa = pd.read_pickle(join(root_folder, \"data\", \"assemblee_nationale\", \"df_mots_cles.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc06d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wtpsplit import SaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat = SaT(\"sat-3l-sm\")\n",
    "sat.half().to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c057d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat.split(df_vsa['content'][], do_paragraph_segmentation=True, paragraph_threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61986dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vsa['bool'] = df_vsa[\"content\"].str.contains(\"Bonjour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cecb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vsa['segmented'] = df_vsa['content'].apply(lambda x: sat.split(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64b11a",
   "metadata": {},
   "source": [
    "# Timeseries & QBert comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a928eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_parquet(\"../../data/activetigger/sicss-an-spacy1000_data_all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66320ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_model_predictions = pd.read_csv('../../data/activetigger/predictions_sicss-an-spacy1000_camembertbase 9 EP__sicss_schreiber__sicss-an-spacy1000__default__02-07-2025_22h08_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e54762",
   "metadata": {},
   "outputs": [],
   "source": [
    "merges = pd.merge(raw_data, at_model_predictions, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merges.to_csv('../../data/activetigger/merged_at_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_date = merges[merges['prediction'] == 'RELEVANT'].groupby(['dataset_datetime', 'prediction']).agg('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_date.to_csv(\"../../grouped_by_date_relevant_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5280c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qbert = pd.read_csv(\"../../data/activetigger/QAmembert_spacy1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "qbert.loc[qbert['score'] >= 0.8].groupby('prediction').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97642f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
