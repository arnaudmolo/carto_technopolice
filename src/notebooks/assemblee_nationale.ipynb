{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d766322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from os import listdir, getcwd\n",
    "from os.path import join, dirname\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0a524",
   "metadata": {},
   "source": [
    "# Assemblee nationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSeance(path, document: str):\n",
    "    path = join(path, document) # generate full path\n",
    "    seance = etree.parse(path) # missing argument error can be ignored\n",
    "\n",
    "    # extract metadata\n",
    "    legislature = seance.find(\".//{http://schemas.assemblee-nationale.fr/referentiel}legislature\").text\n",
    "    date = seance.find(\".//{http://schemas.assemblee-nationale.fr/referentiel}dateSeance\").text\n",
    "\n",
    "    # init list for text extraction\n",
    "    text_list = []\n",
    "\n",
    "    # loop over all speakers\n",
    "    for a in seance.findall(\".//{http://schemas.assemblee-nationale.fr/referentiel}orateur\"):\n",
    "        paragraphe = a.getparent().getparent() # the paragraph is two nodes up from the speaker\n",
    "        if paragraphe.tag != '{http://schemas.assemblee-nationale.fr/referentiel}paragraphe': # this basically catches a \"vote\" result block\n",
    "            continue\n",
    "        valeur_ptsodj = paragraphe.get('valeur_ptsodj') # ordre du jour\n",
    "        code_grammaire = paragraphe.get('code_grammaire') # type of speech\n",
    "        ordre_absolu_seance = paragraphe.get(\"ordre_absolu_seance\") # index number\n",
    "        ordinal_prise = paragraphe.get(\"ordinal_prise\") # another index number\n",
    "        orateur_name = a.find('{http://schemas.assemblee-nationale.fr/referentiel}nom') # name of the speaker\n",
    "        orateur_name_str = etree.tostring(orateur_name, method=\"text\", encoding=\"unicode\").strip()\n",
    "        orateur_id = a.find('{http://schemas.assemblee-nationale.fr/referentiel}id') # id of the speaker\n",
    "        orateur_ref = a.find('{http://schemas.assemblee-nationale.fr/referentiel}acteurRef') # this is only to catch errors with the 15th legislature\n",
    "        if orateur_id is not None:\n",
    "            orateur_id = orateur_id\n",
    "        elif orateur_ref is not None:\n",
    "            orateur_id = orateur_ref\n",
    "        else:\n",
    "            orateur_id = etree.fromstring(text=\"<orateur>None</orateur>\") # default to None if nothing found\n",
    "        orateur_id_str = etree.tostring(orateur_id, method=\"text\", encoding=\"unicode\").strip()\n",
    "        content = paragraphe.find(\"{http://schemas.assemblee-nationale.fr/referentiel}texte\") # extract the text\n",
    "        content_str = etree.tostring(content, method=\"text\", encoding=\"unicode\").strip()\n",
    "        talking = {'legislature': legislature,\n",
    "                   'nom_fichier': document,\n",
    "                   'date': date,\n",
    "                   'orateur_name' : orateur_name_str,\n",
    "                   'orateur_id' : orateur_id_str,\n",
    "                   'ordre_absolu_seance': int(ordre_absolu_seance),\n",
    "                   'valeur_ptsodj': int(valeur_ptsodj),\n",
    "                   'ordinal_prise': ordinal_prise,\n",
    "                   'code_grammaire': code_grammaire,\n",
    "                   'content' : content_str}\n",
    "        text_list.append(talking)\n",
    "    return text_list # returns a list of all speech nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd20304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip Assemblee nationale opendata and keep only \"compteRendu\" and put them in \"data/assemblee_nationale\"\n",
    "folders = [\"15_compteRendu\", \"16_compteRendu\", \"17_compteRendu\"]\n",
    "root_folder = dirname(dirname(getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7514847",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    path = join(root_folder, \"data\", \"assemblee_nationale\", folder)\n",
    "    for f in listdir(path):\n",
    "        if f == 'CRSJOCGR5L15S2017E1N001.xml': # this file is a duplicate, so we exclude it\n",
    "            continue\n",
    "        cr = parseSeance(path, f)\n",
    "        all_cr.extend(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42edb31",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b20384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame(all_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73944d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning \n",
    "df[\"date\"] = df[\"date\"].str[:12]\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"date\"])\n",
    "match_weird_punctuation = re.compile(r'([!\\.,)?])(?=\\w)')\n",
    "df['content'] = df['content'].str.replace(match_weird_punctuation, r'\\1 ', regex=True) # catches punctuation errors\n",
    "df['content'] = df['content'].str.replace('\\xa0', ' ') # catches white spaces\n",
    "df['content'] = df['content'].str.replace('gouvernement', 'Gouvernement') # both spellings exist in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grouped df to take into account interruptions\n",
    "# Groups by \"ordre du jour\" and only if it's a \"parole générique\" (no interruption)\n",
    "\n",
    "df_paroles = df.loc[df[\"code_grammaire\"] == \"PAROLE_GENERIQUE\"]\n",
    "df_rest = df.loc[df[\"code_grammaire\"] != \"PAROLE_GENERIQUE\"]\n",
    "\n",
    "df_grouped = (\n",
    "    df_paroles.groupby(['legislature', 'datetime', 'orateur_id', 'valeur_ptsodj'], as_index=False)\n",
    "    .agg({\n",
    "        'orateur_name': 'first',\n",
    "        'content': ' ; '.join,\n",
    "        'ordre_absolu_seance': list,\n",
    "        'code_grammaire': 'first'\n",
    "    })\n",
    ")\n",
    "\n",
    "df_grouped = pd.concat([df_grouped, df_rest], ignore_index=True)\n",
    "df_grouped = df_grouped.sort_values(\n",
    "    by=['datetime', 'valeur_ptsodj', 'ordre_absolu_seance'],\n",
    "    key=lambda col: col.map(\n",
    "        lambda x: x if col.name == 'datetime' else x if col.name == 'valeur_ptsodj' else (x[0] if isinstance(x, list) and len(x) > 0 else float(x))\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "df_grouped = df_grouped.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a631730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun stats\n",
    "df.loc[df[\"code_grammaire\"].str.contains(\"PAROLE\")][\"content\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf19ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by keywords\n",
    "\n",
    "df_vsa = df_grouped.loc[\n",
    "    df_grouped[\"content\"].str.contains(\"vidéo-surveillance\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"vidéo-protection\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"vidéosurveillance\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"vidéoprotection\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"vie privée\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"RGPD\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"caméras de surveillance\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"caméra de surveillance\", case=False)\n",
    "    | df_grouped[\"content\"].str.contains(\"VSA\", case=False)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
